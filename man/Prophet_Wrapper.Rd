% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ProphetWrapper.R
\name{Prophet_Wrapper}
\alias{Prophet_Wrapper}
\title{Prophet Wrapper}
\usage{
Prophet_Wrapper(df, list_params, holidays = NULL, best_model_in = "test",
  plotFrom = NULL, main_accuracy_metric = "MAPE",
  train_set_imp_perc = 0.5, judgmental_forecasts = NULL, k_impute = 2,
  method_impute = "exponential", parallel = FALSE, seed = 12345,
  period_cv = NULL, initial_cv = NULL, horizon_cv = NULL,
  final_predictions = NULL, testing_period = NULL, debug = FALSE)
}
\arguments{
\item{df}{A data-frame with a numeric column, a date type column, a regressor and a column train (for train/test split). The 'train' column has to have 1 and 0 only where 1 refer to training set.}

\item{list_params}{A list with the following parameters:
 \itemize{
 \item{\strong{target_variable}}  {The name of the target variable to predict. Has to be included in df.}
 \item{\strong{changepoint.prior.scale}}  {A regularization parameter (vector or single value) for the automatic changepoint definitions of Prophet to define piecewise trend blocks. If the trend changes are being overfit (too much flexibility) or underfit (not enough flexibility), you can adjust the strength of this argument. By default Prophet sets this parameter to 0.05. Increasing it will make the trend more flexible.}
 \item{\strong{regressor.prior.scale}}  {A regularization parameter (vector or single value) for the external regressor. If the regressor is being overfit (too much flexibility) or underfit (not enough flexibility), you can adjust the strength of this argument. By default Prophet sets this parameter to 0.05. Increasing it will make the effect of regressor more flexible. This parameter is applied to both regressor1 and regressor2 (if parsed).}
 \item{\strong{holidays.prior.scale}}   {A regularization parameter (vector or single value) for the holidays effects. If the regressor is being overfit (too much flexibility) or underfit (not enough flexibility), you can adjust the strength of this argument. By default this parameter is 10, which provides very little regularization. Reducing this parameter dampens holiday effects. Increasing it will make the holidays effect more flexible.}
 \item{\strong{seasonality.prior.scale}}   {A regularization parameter (vector or single value) for the seasonality effects. If the regressor is being overfit (too much flexibility) or underfit (not enough flexibility), you can adjust the strength of this argument. By default this parameter is 10, which provides very little regularization. Reducing this parameter dampens seasonality effects. Increasing it will make the holidays effect more flexible.}
 \item{\strong{weekly.seasonality}}  {Fit weekly seasonality. Can be 'auto', TRUE, FALSE, or a number of Fourier terms to generate.}
 \item{\strong{yearly.seasonality}}  {Fit yearly seasonality. Can be 'auto', TRUE, FALSE, or a number of Fourier terms to generate.}
 \item{\strong{daily.seasonality}}  {Fit daily seasonality. Can be 'auto', TRUE, FALSE, or a number of Fourier terms to generate.}
 \item{\strong{regressor1}}  {The name of the first external regressor (or regressors) to include in the model. It has to exist on df as a column. If a vector is parsed, 1 regressor at a time is tested (as a model parameter essentially). If "no_regressor" is parsed, a univariate time-series model is estimated. "no_regressor" can be parsed as an element of the vector as well. }
 \item{\strong{regressor2}}  {The name of the second external regressor (or regressors) to include in the model. It has to exist on df as a column. If a vector is parsed, 1 regressor at a time is tested (in combination with regressor1 if parsed). If "no_regressor" is parsed, a univariate time-series model is estimated. "no_regressor" can be parsed as an element of the vector as well. }
 \item{\strong{standardize_regressor}}  {Specify whether this regressor will be standardized prior to fitting. Can be 'auto' (standardize if not binary), True, or False.}
 \item{\strong{log_transformation}}  {Bool, specify whether the Target Variable will be log transformed pre-fitting the models or not.}
}}

\item{holidays}{A data-frame with columns holiday (character) and ds (date type) and optionally columns lower_window and upper_window which specify a range of days around the date to be included as holidays. lower_window=-2 will include 2 days prior to the date as holidays. Also optionally can have a column prior_scale specifying the prior scale for each holiday. It defaults to NULL in which case no holidays are used.}

\item{best_model_in}{A character value either: 'train', 'test', 'mix_train_test' or 'cv'. Defaults to 'test'. This parameter defines the criteria to pick the best model - either based on accuracy on training set or in test set. The user might have different business requirements and wants to understand the general performance of the model cross-validated over a set of periods ('cv').}

\item{plotFrom}{A character value ('yyyy-mm-dd') representing a date to filter the data from to plot the best model based on the 'best_model_in' parameter (actuals vs forecast).}

\item{main_accuracy_metric}{A character value either: 'MAPE', 'MSE', 'MAE', 'RMSE' or MPE (it defaults to MAPE). This defines the criteria for selecting the best model (together with the 'best_model_in' parameter).}

\item{train_set_imp_perc}{A numeric input between 0 and 1 representing the weight to give to the training set results relatively to the test set. Defaults to 0.5 (mean results). This parameter only affects the results when 'best_model_in' is set to 'mix_train_test'. When set to 1 the results are the same as setting 'best_model_in' to 'train'.}

\item{judgmental_forecasts}{A names vector with the date as name and the value of the judmental forecast. For example if we know in advance that on the Xmas day the value we are trying to predict is zero we can parse judgmental_forecasts = c('2016-12-25' = 0,  '2017-12-25' = 0, '2018-12-25' = 0).}

\item{k_impute}{Integer width of the moving average window. Expands to both sides of the center element e.g. k=2 means 4 observations (2 left, 2 right) are taken into account. If all observations in the current window are NA, the window size is automatically increased until there are at least 2 non-NA values present (from ImputeTS package). Defaults to 2.}

\item{method_impute}{Weighting method to be used for imputing missing values or padded time-series. Accepts the following input: "simple" - Simple Moving Average (SMA), "linear" - Linear Weighted Moving Average (LWMA) or "exponential" - Exponential Weighted Moving Average (EWMA). Defaults to 'exponential'.}

\item{parallel}{A Bool specify wheter to use parallelization whilst training the different models or not (defaults to FALSE). If TRUE, the number of cores is set to the total number of available cores minus 1 (parallel::detectCores()-1).}

\item{seed}{A seed.}

\item{period_cv}{Used if best_model_in == 'cv'. Integer amount of time between cutoff dates. Same units as horizon. If not provided, 0.5 * horizon is used (for more details see documentation of prophet::cross_validation function and/or check Details section below).}

\item{initial_cv}{Used if best_model_in == 'cv'. Integer size of the first training period. If not provided, 3 * horizon is used. Same units as horizon (for more details see documentation of prophet::cross_validation function and/or check Details section below).}

\item{horizon_cv}{Used if best_model_in == 'cv'. Integer size of the horizon (for more details see documentation of prophet::cross_validation function and/or check Details section below).}

\item{final_predictions}{final_predictions is the argument that will control the length/horizon of the final forecasts (the forecast generated from the optimised model trained on all available data). The values of final_predictions argument can be:
 \itemize{
 \item{\strong{integer}}  {If final_predictions is set to an integer, the final forecast horizon will have length final_predictions. Please note that if the final forecast uses regressors, these have to be parsed here as a data.frame (see below).}
 \item{\strong{data.frame}} {A data.frame with columns 'Date', 'regressor1' and 'regressor2' with the future values of the regressors. If regressors are not used then an integer value can be used.}
 \item{\strong{ProphetWrapper Object}} {The user can parse directly a ProphetWrapper object (output of Prophet_Wrapper function). This reveals to be useful when using 'stacked' modelling. The regressors used are the Final_Forecasts from the ProphetWrapper object parsed and the length/horizon of the final forecasts is the number of future rows in Final_Forecasts.}
 \item{\strong{NULL (default)}} {If set to NULL, final_predictions is set to the length of the test set (assumes the test set is representative of the future horizon.)}
}}

\item{testing_period}{An integer value representing the length/horizon of the testing period. There is no default since the test period is critical for ProphetWrapper's functionality.}

\item{debug}{TRUE for browsing the function. Defaults to FALSE.}
}
\value{
This function returns a list of class 'ProphetWrapper' with the following elements:
 \itemize{
\item{\strong{Final_Forecasts:}} {A data-frame with final forecasts on unseen data produced by training the optimised model (based on 'main_accuracy_metric' and 'best_model_in' parameters) on the entire data. The user can use the 'final_predictions' parameter to control the horizon of the final forecasts (more detail on the function documentation). ProphetWrapper class object can be parsed directly to 'final_predictions' which reveals to be useful when using 'stacked' modelling. The regressors used are the Final_Forecasts from the ProphetWrapper object parsed and the length/horizon of the final forecasts is the number of future rows in Final_Forecasts. The forecast length (horizon) can also be set to be equal to the length of the test set (when 'final_predictions' is NULL) or to a specified integer.}
\item{\strong{Accuracy_Overview:}} {A data-frame with the performance of all the models estimated with a flag for the best model (based on 'main_accuracy_metric' and 'best_model_in' parameters). The error metrics available are: MAPE, MSE, MAE, RMSE and MPE.}
\item{\strong{Actuals_vs_Predictions_All:}} {A data-frame with point predictions vs actuals, upper and lower bound predictions as per Prophet and other details about the series and the models (for train and test set). There is a row per date and model trained pair (i.e. if n models are trained this data-frame returns n rows for each of the date points).}
\item{\strong{Actual_vs_Predictions_Best:}} {A data-frame with the predictions of the best model (selected based on 'main_accuracy_metric' and 'best_model_in' parameters). Actuals, predictions, upper and lower bound predictions are included as well as a 'prediction_and_predictor' field wich contains actuals from the train set and predictions from the test set (useful when stacked models are used).}
\item{\strong{Best_Parameters:}} {A data-frame with the best parameters used to estimate the best model (selected based on 'main_accuracy_metric' and 'best_model_in' parameters).}
\item{\strong{CV_Overview:}} {A data-frame with an overview of the in-fold accuracy performance for the best model (selected based on 'main_accuracy_metric' and 'best_model_in' parameters). This output is only made available if best_model_in parameter is set to 'cv'.}
\item{\strong{Plot_CV_Accuracy:}} {A ggplot graph illustrating the performance on cross-validation for different horizon (look-ahead) periods. This output is only made available if best_model_in parameter is set to 'cv'.}
\item{\strong{Plot_Actual_Predictions:}} {A ggplot graph of Actuals vs Predictions. The 'plotFrom' parameter controls from when to plot from.}
}
}
\description{
This is a function that wraps up (\href{https://facebook.github.io/prophet/docs/installation.html}{Prophet}) package functionality, expanding the possibilities currently offered by the Facebook developed R package.
The main rationale behind the package was to build a reproducible function to model and test several models simultaneously. The package currently offers grid.search functionality for parameter tuning, results/accuracy visualisations and cross-validation.
}
\details{
Since this is a wrapper for Prophet, you can find extra parameters information on Prophet documentation \code{?prophet}.

When the parameter 'best_model_in' is set to 'cv' cross-validation (cv) will be performed. More precisely, due to the chronological nature of the data (time-series) the cv method used is 'evaluation on a rolling forecasting origin'. ProphetWrapper uses the prophet::cross_validation() function to compute this error metrics.
Three arguments can be selected for this section (horizon_cv, period_cv and initial_cv). horizon_cv controls for the length of each of the forecasts in the cross-validation process (defaults to the size of the testing set parsed to prophet_wrapper). The initial_cv controls for the length of the minimum data used for training on each fold (defaults to 3 * horizon_cv). period_cv controls for the time between cut-offs controlling if they overlap or not.
As an example assuming daily data, if we have 1673 observations finishing on the 2018-07-31 and we select horizon_cv equal to 91, period equal to 89 and initial as 1673 - 270, we end up with 3 folds of 90 days each sequentially.
}
\examples{
\dontrun{

parameters = list(changepoint.prior.scale = c(0.2, 0.3),
regressor.prior.scale = c(0.01, 0.02),
weekly.seasonality = TRUE,
yearly.seasonality = TRUE,
daily.seasonality = TRUE,
standardize_regressor = TRUE,
log_transformation = TRUE,
target_variable = "y",
regressor1 = "x",
regressor2 = "z" )


test = Prophet_Wrapper(df = df_example,
                    list_params = parameters,
                    holidays = holidays,
                    best_model_in = "train",
                    main_accuracy_metric = "MAPE",
                    train_set_imp_perc = 0.5,
                    final_predictions = list(forecasts_inbound_all, forecasts_offered_all)

}

}
